{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus preprocessing: NLTK toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a corpus\n",
    "\n",
    "You can find corpus in scikit-learn or NLTK, even, you can download documents from wikipedia. One useful corpus to work in brown, from the NLTK toolbox. This corpus has ten categories, so you can apply classfication methods after getting a topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document preprocessing\n",
    "\n",
    "Here, you should convert every word to lowercase,  remove punctuation, stemming, remove stopwords.... It is advisable that you start to work with a single document, design your functions and, afterwards, you create a function to clean a document and apply it over all the documents of your corpus.\n",
    "\n",
    "The output of this section should be a ''clean corpus''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature creation\n",
    "\n",
    "From the clean corpus created in the previous section, we are going to start creating our features a bag of words (bow) representation and a TF-IDF values.\n",
    "\n",
    "For this purpose,  we can use the gensim functions, since this will make easier train the following topic models. For this purpose, follow this steps:\n",
    "1. Create a gensim dictionary\n",
    "2. Compute the bow\n",
    "3. Get the TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling: Gensim toolbox\n",
    "\n",
    "Here, let's train the LSI and LDA models using the gensim tools. Train both models and examine the topics provided by ech model and the representation of each document over the topic space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Classification \n",
    "\n",
    "Apply any classification tool to evaluate the advantages provided by the document representation over the topics of both LSI and LDA models; if you want, you can compare it with the bag of words features or the TF-IDF ones to use these representations as baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
